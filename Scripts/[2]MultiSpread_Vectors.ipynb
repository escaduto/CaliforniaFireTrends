{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[2]MultiSpread_Vectors.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"h18sWCos3-p1"},"source":["# Quantify Day-to-Day Multidirectional Spread "]},{"cell_type":"markdown","metadata":{"id":"tFonS8q4pRWj"},"source":["## Setup Connection to Drive"]},{"cell_type":"code","metadata":{"id":"eMCHZj6PpL3w","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1600893599654,"user_tz":420,"elapsed":702,"user":{"displayName":"Erica Scaduto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_Xg3Y--EQFQ6RVDUS0SoJsVKUb6AOaaVkYu-7=s64","userId":"04192059296941555235"}},"outputId":"7cd72aa5-301a-44ba-cb85-3f53984b23ab"},"source":["from google.colab import drive # import drive from google colab\n","ROOT = \"/content/drive\"     # default location for the drive\n","print(ROOT)                 # print content of ROOT (Optional)\n","\n","drive.mount(ROOT)           # we mount the google drive at /content/drive"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y237qvlb5kwV"},"source":["import os\n","rootPath = \"/content/drive/My Drive/California FireTrends (2012-2020)\"\n","os.chdir(rootPath)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FR9lyCrI3Zx4"},"source":["<b>Multi-Directional Spread</b>\n","<n>Use 'trace-back' and 'back-fill' method where shortest distance from points across firefront back to previous day shared line is calculated.\n","\n","1. Get smoothed interpolated daily perimeters \n","2. Get shared fire-line Day1 & Day 2\n","3. Points along front line and shared line \n","4. Find shortest distance from front line back to shared line \n","\n","For days > 1 then shared fireline can be past two days. "]},{"cell_type":"code","metadata":{"id":"AKWPRLgz3aX8"},"source":["def lstFiles(rootPath, ext):\n","  '''\n","  retrieve file path + names based on extension\n","  '''\n","  file_list = []\n","  root = rootPath\n","  for path, subdirs, files in os.walk(root):\n","      for names in files: \n","          if names.endswith(ext):\n","              file_list.append(os.path.join(path,names))\n","  return file_list\n","\n","def createFolder(rootPath, folderName): \n","  '''\n","  Create new folder in root path \n","  '''\n","  folderPath = os.path.join(rootPath, folderName) \n","  if not os.path.exists(folderPath):\n","      os.makedirs(folderPath)\n","  return folderPath \n","\n","\n","def listFiles(rootPath):\n","  '''\n","  retrieve file path + names \n","  '''\n","  file_list = []\n","  root = rootPath\n","  for path, subdirs, files in os.walk(root):\n","    for names in files: \n","      file_list.append(os.path.join(path,names))\n","  return file_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"10zdJRGjyQPZ"},"source":["import pandas as pd\n","from scipy.spatial.distance import cdist\n","\n","def closest_point(point, points):\n","    \"\"\" Find closest point from a list of points. \"\"\"\n","    return points[cdist([point], points).argmin()]\n","\n","def match_value(df, col1, x, col2):\n","    \"\"\" Match value x from col1 row to value in col2. \"\"\"\n","    return df[df[col1] == x][col2].values[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kH2eQUcPyQPc"},"source":["import math\n","from math import radians, degrees, sin, cos, asin, acos, sqrt\n","# def calculateDistance(pointA, pointB):\n","#     lat1 = math.radians(pointA[0])\n","#     lat2 = math.radians(pointB[0])\n","#     lon1 = math.radians(pointA[1])\n","#     lon2 = math.radians(pointB[1])\n","#     return 6371 * (\n","#         acos(sin(lat1) * sin(lat2) + cos(lat1) * cos(lat2) * cos(lon1 - lon2))\n","#     )\n","\n","def calculate_initial_compass_bearing(pointA, pointB):\n","    \"\"\"\n","    Calculates the bearing between two points.\n","    The formulae used is the following:\n","        θ = atan2(sin(Δlong).cos(lat2),\n","                  cos(lat1).sin(lat2) − sin(lat1).cos(lat2).cos(Δlong))\n","    :Parameters:\n","      - `pointA: The tuple representing the latitude/longitude for the\n","        first point. Latitude and longitude must be in decimal degrees\n","      - `pointB: The tuple representing the latitude/longitude for the\n","        second point. Latitude and longitude must be in decimal degrees\n","    :Returns:\n","      The bearing in degrees\n","    :Returns Type:\n","      float\n","    \"\"\"\n","    if (type(pointA) != tuple) or (type(pointB) != tuple):\n","        raise TypeError(\"Only tuples are supported as arguments\")\n","\n","    lat1 = math.radians(pointA[0])\n","    lat2 = math.radians(pointB[0])\n","\n","    diffLong = math.radians(pointB[1] - pointA[1])\n","\n","    x = math.sin(diffLong) * math.cos(lat2)\n","    y = math.cos(lat1) * math.sin(lat2) - (math.sin(lat1)\n","            * math.cos(lat2) * math.cos(diffLong))\n","\n","    initial_bearing = math.atan2(x, y)\n","\n","    # Now we have the initial bearing but math.atan2 return values\n","    # from -180° to + 180° which is not what we want for a compass bearing\n","    # The solution is to normalize the initial bearing as shown below\n","    initial_bearing = math.degrees(initial_bearing)\n","    compass_bearing = (initial_bearing + 360) % 360\n","\n","    return compass_bearing"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aLw7a2sC3nc8","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600372157729,"user_tz":420,"elapsed":685,"user":{"displayName":"Erica Scaduto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_Xg3Y--EQFQ6RVDUS0SoJsVKUb6AOaaVkYu-7=s64","userId":"04192059296941555235"}},"outputId":"ff4c915f-ac70-4df9-eba1-9bafe45c6e5c"},"source":["pointA = (41.01293623, -122.04922577)\n","pointB = (41.01176303, -122.03467066)\n","calculate_initial_compass_bearing(pointB, pointA)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["276.1020670509466"]},"metadata":{"tags":[]},"execution_count":126}]},{"cell_type":"code","metadata":{"id":"QdwPChD2Bkqy"},"source":["%%time \n","\n","# Important library for many geopython libraries\n","!apt install gdal-bin python-gdal python3-gdal \n","# Install rtree - Geopandas requirment\n","!apt install python3-rtree \n","# Install Geopandas\n","!pip install git+git://github.com/geopandas/geopandas.git\n","# Install descartes - Geopandas requirment\n","!pip install descartes \n","# Install Folium for Geographic data visualization\n","!pip install folium\n","# Install plotlyExpress\n","!pip install plotly_express"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Htx69XjBpvB"},"source":["import pandas as pd\n","import numpy as np\n","import geopandas as gpd\n","from shapely.geometry import Point\n","import matplotlib\n","import matplotlib.pyplot as plt \n","import folium\n","import rtree"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AaTJWVa04wVa"},"source":["## Get Derived Fire Info"]},{"cell_type":"code","metadata":{"id":"V8kZCP2s4Xmq"},"source":["fireInfo = pd.read_csv('Products/DerivedFireInfo_Total.csv', index_col=0)\n","fireInfo"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J-f22N_B5U71"},"source":["## Filter to 85% of Cumulative Burn Area"]},{"cell_type":"code","metadata":{"id":"XzXONP-449_a"},"source":["\n","def filterOutPerimeter(path):\n","  # read in derived geo with geopandas \n","  new_path = path.replace('By_Fire', 'By_Fire_Filtered')\n","  if os.path.exists(new_path) == False: \n","    # print(path)\n","    gdf = gpd.read_file(path)\n","\n","    # get aggregated fire count \n","    fireCount = gdf.groupby(['Fire', 'Year'])\n","    cumudf = fireCount.agg({'JulianDay' : ['count'] , 'Area (ha)' : ['sum']}).reset_index()\n","    cumudf.columns = ['Fire', 'Year', 'Original Total Days', 'Original Total Area']\n","    \n","    # calculate percent cumulative burn \n","    newDF = gdf.merge(cumudf, on=['Fire', 'Year'])\n","    newDF['Ratio'] = newDF['Area (ha)']  / newDF['Original Total Area'] \n","    newDF['cumsum'] = newDF.groupby(['Fire', 'Year'])['Ratio'].cumsum() \n","\n","    # filter, keep top 85% \n","    newDF = newDF[(newDF['Original Total Days'] < 6) | (newDF['cumsum'] <= .85)]\n","    newCount = newDF.groupby(['Fire', 'Year'])\n","    newCount = newCount.agg({'JulianDay' : ['count'] , 'Area (ha)' : ['sum']}).reset_index()\n","    newCount.columns = ['Fire', 'Year', 'Filtered Total Days', 'Filtered Total Area']\n","    new = newDF.merge(newCount, on=['Fire', 'Year'])\n","     \n","    # save filtered geometries\n","    file_nm = os.path.basename(new_path)\n","    new_directory = new_path.replace(file_nm, '')\n","\n","    if not os.path.exists(new_directory):\n","        os.makedirs(new_directory)\n","\n","    new.to_file(new_path)\n","\n","    print('filtered', file_nm)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f4hVPAXi5oVm"},"source":["interFiles = lstFiles(os.path.join(r'Products', 'By_Fire'), '.shp')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IHmXHwYA6xKn"},"source":["for shp_path in interFiles: \n","  filtered_df = filterOutPerimeter(shp_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gntUSrffJDY8"},"source":["filteredFiles = lstFiles(os.path.join(r'Products', 'By_Fire_Filtered'), '.shp')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pv_t-jQMsAX7","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600373395860,"user_tz":420,"elapsed":639,"user":{"displayName":"Erica Scaduto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_Xg3Y--EQFQ6RVDUS0SoJsVKUb6AOaaVkYu-7=s64","userId":"04192059296941555235"}},"outputId":"14a2cc6c-ba30-4536-e458-32eb436335e9"},"source":["filteredFiles[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Products/By_Fire_Filtered/2018/Ferguson/Ferguson_2018_NAT.shp'"]},"metadata":{"tags":[]},"execution_count":154}]},{"cell_type":"markdown","metadata":{"id":"WxztjyjguzQc"},"source":["## Get Daily Spread Info\n","\n","Distance, Direction\n"]},{"cell_type":"markdown","metadata":{"id":"-qvnEb5Tu8Ox"},"source":["### Get Ignition"]},{"cell_type":"code","metadata":{"id":"LCNBD6jRMjyl"},"source":["# rename \n","ignition_files = listFiles('Ignition/Ignition_Points')\n","\n","for fls in ignition_files:\n","  pth = os.path.dirname(fls)\n","  oldname = os.path.basename(fls)\n","  newname = oldname.strip().replace(' ', '')\n","  os.rename(os.path.join(pth, oldname), os.path.join(pth, newname))\n","  print(newname)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FhG74HnYRndG"},"source":["def getIgnitionDF(poly_path):\n","  ignition_pth = poly_path.replace('Products', 'Ignition')\n","  ignition_pth = ignition_pth.replace('By_Fire', 'Ignition_Points')\n","  ignition_pth = ignition_pth.replace('NAT', 'IgnitionPnts')\n","  ignition_gdf = gpd.read_file(ignition_pth)\n","  return ignition_gdf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OO50NeRWvC9d"},"source":["### Generate Points Along Bounds"]},{"cell_type":"code","metadata":{"id":"LgVoMTP_uM3e"},"source":["def generatePointsAlongLine(firebounds_df):\n","  points_along_line = []\n","  for len in range(1, 1000, 1):\n","    len_per = len/1000\n","    points_along_line.append(firebounds_df.boundary.interpolate(len_per, normalized=True)[0])\n","  \n","  d = {'geometry': points_along_line}\n","  boundsToPoints_df = gpd.GeoDataFrame(d, crs= firebounds_df.crs)\n","  return boundsToPoints_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FdDvbB47kkFv"},"source":["### Visualize Spread Vectors\n"]},{"cell_type":"code","metadata":{"id":"INY9RUBLkniy"},"source":["def visualizeVectors(df, poly_df):\n","  start_gdf = gpd.GeoDataFrame(df, geometry='start_coord').set_crs('EPSG:3310').reset_index(drop=True)\n","  end_gdf = gpd.GeoDataFrame(df, geometry='end_coord').set_crs('EPSG:3310').reset_index(drop=True)\n","  line_gdf = gpd.GeoDataFrame(df, geometry='line_coord').set_crs('EPSG:3310').reset_index(drop=True)\n","  \n","  line_gdf_clipped = gpd.clip(line_gdf, poly_df.geometry.buffer(0.01))\n","  line_gdf_clipped['line_distance'] = line_gdf_clipped['line_coord'].length\n","\n","  # base = start_gdf.plot(color='black', markersize=1)\n","  # end_gdf.plot(ax=base, marker='o', color='green', markersize=1) \n","  # line_gdf_clipped.plot(ax=base, color='red', alpha=0.4)  \n","  return line_gdf_clipped"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V3ntwCPFvIm8"},"source":["### First Day Spread"]},{"cell_type":"code","metadata":{"id":"JJrQqICaS6Su"},"source":["import geopandas as gpd\n","from shapely.geometry import mapping\n","from shapely.ops import nearest_points\n","\n","def firstDaySpread(day_num, poly_path, firstDay):\n","  firefront_df = generatePointsAlongLine(firstDay)\n","  startPnt_df = getIgnitionDF(poly_path)\n","\n","  nearest_df = findNearestPoint(startPnt_df.geometry, firefront_df.geometry)\n","\n","  df = getSpreadInfo(nearest_df, firstDay.Date[0], firstDay.Year[0], firstDay.Fire[0]) \n","\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b1xdCsCOtP8M"},"source":["def generateDayPairs(gdf):\n","  days = gdf['JulianDay'].tolist()\n","  dayPairs = list(zip(days, days[1:] + days[:1])) \n","  dayPairs = dayPairs[:-1] \n","  return dayPairs\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x7SPLbRC8lfb"},"source":["from shapely.ops import nearest_points\n","\n","def findNearestPoint(prevDay_pnts, currDay_pnts):\n","  # unary union of the gpd2 geomtries \n","  prevDay_Multipoint = prevDay_pnts.geometry.unary_union\n","  \n","  def near(pnt1, pts=prevDay_Multipoint):\n","      # find the nearest point and return the corresponding Place value\n","      curr_pnt, closest_pnt = [o.wkt for o in nearest_points(pnt1, pts)]\n","      return curr_pnt, closest_pnt\n","      \n","  nearest = currDay_pnts.apply(lambda x: near(x))\n","\n","  current_Point = [] \n","  closest_Point = [] \n","\n","  for A, B in nearest: \n","    current_Point.append(A)\n","    closest_Point.append(B)\n","\n","  nearstPointsPair = pd.DataFrame({'Current_Day' : current_Point ,'Nearest_Point' : closest_Point })\n","\n","  return nearstPointsPair"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PDeIe98nRidA"},"source":["### Create GeoDataFrame from listo of Points (XY)"]},{"cell_type":"code","metadata":{"id":"p1F59_iSRh2R"},"source":["from shapely import wkt\n","\n","def createGeoDataFrame(pointList):\n","  dic = {'geometry' : map(wkt.loads, pointList)}\n","  df =  gpd.GeoDataFrame(dic, geometry='geometry')\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"it_pCTEmA3oL"},"source":["### Calculate distance and direction, save into df"]},{"cell_type":"code","metadata":{"id":"2kgYb4xVVYRg"},"source":["import shapely.wkt\n","\n","def calculateDistDir(date, year, fire, currentPoints, startPoints):\n","\n","  distance = [] \n","  direction = [] \n","  start_coord = [] \n","  end_coord = [] \n","  dt = [] \n","  fire_name = []\n","  yr = []\n","  line_coord = []\n","\n","  for endpnt, startpnt in list(zip(currentPoints, startPoints)):\n","      # get distance\n","      distance.append(startpnt.distance(endpnt))\n","      \n","      # get direction \n","      start_pnt_coord = (startpnt.x, startpnt.y)\n","      end_pnt_coord = (endpnt.x, endpnt.y)\n","      direction.append(calculate_initial_compass_bearing(start_pnt_coord, end_pnt_coord))\n","\n","      start_coord.append(startpnt)\n","      end_coord.append(endpnt)\n","      line_coord.append(LineString([(startpnt.x, startpnt.y), (endpnt.x, endpnt.y)]))\n","      \n","      \n","      dt.append(date)\n","      fire_name.append(fire)\n","      yr.append(year)\n","      \n","  daily_spread_Info = pd.DataFrame({'Fire' : fire_name, 'Year':yr, 'Date': dt,\n","                                      'distance': distance, 'direction':direction, \n","                                      'start_coord': start_coord, 'end_coord':end_coord,\n","                                      'line_coord': line_coord})\n","  return daily_spread_Info"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lkjo-64EA09T"},"source":["### Extract spread info"]},{"cell_type":"code","metadata":{"id":"Jds2eDbwTIdt"},"source":["from shapely.geometry import Point, LineString\n","from shapely import geometry, ops\n","\n","def getSpreadInfo(nearstPointsPair, date, year, fire): \n","  PNT_A = nearstPointsPair['Current_Day'].tolist()\n","  PNT_B = nearstPointsPair['Nearest_Point'].tolist()\n","  \n","  currentPoints = map(wkt.loads, PNT_A)\n","  startPoints = map(wkt.loads, PNT_B)\n","\n","  backfill_df = calculateDistDir(date, year, fire, currentPoints, startPoints)\n","  \n","\n","  # for points that overlap; backfill from previous day to fire front \n","  start_gdf = gpd.GeoDataFrame(backfill_df, geometry='start_coord').set_crs('EPSG:3310')\n","  end_gdf = gpd.GeoDataFrame(backfill_df, geometry='end_coord').set_crs('EPSG:3310')\n","\n","  new_end_points = end_gdf[end_gdf['distance'] > 100]['end_coord']\n","  new_start_points = start_gdf[start_gdf['distance'] < 100]['start_coord']\n","\n","  if len(new_start_points) > 1: \n","    new_nearest_df = findNearestPoint(new_end_points, new_start_points)\n","    \n","    new_PNT_A = new_nearest_df['Current_Day'].tolist()\n","    new_PNT_B = new_nearest_df['Nearest_Point'].tolist()\n","\n","    new_currentPoints = map(wkt.loads, new_PNT_A)\n","    new_startPoints = map(wkt.loads, new_PNT_B)\n","    \n","    frontfill_df = calculateDistDir(date, year, fire, new_startPoints, new_currentPoints)\n","\n","    frames = [frontfill_df, backfill_df]\n","    result = pd.concat(frames)\n","\n","    return result\n","  else: \n","    return backfill_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1fs9xj4DAuAh"},"source":["### Final magnitude"]},{"cell_type":"code","metadata":{"id":"US1_4vUunSV5"},"source":["def getFinalMagnitude(fire_poly):\n","  gdf = gpd.read_file(fire_poly)\n","  # gdf.to_crs('EPSG:4326')\n","  gdf = gdf.sort_values(by=['JulianDay'])\n","\n","  daypairs = generateDayPairs(gdf) \n","  for day_num in range(-1, len(daypairs)-1):\n","    if day_num == -1 : \n","      # get first day df \n","      firstDay = gdf[:1]\n","      df = firstDaySpread(day_num, fire_poly, firstDay)\n","      df = visualizeVectors(df, firstDay) \n","      # append df\n","      complete_df_byFire.append(df)\n","    \n","    else: \n","      prevDay = gdf[day_num:day_num+1].reset_index()\n","      currDay = gdf[day_num+1:day_num+2].reset_index()\n","            \n","      prevDay_pnts = generatePointsAlongLine(prevDay)\n","      currDay_pnts = generatePointsAlongLine(currDay)\n","\n","      nearest_df = findNearestPoint(prevDay_pnts, currDay_pnts.geometry)\n","\n","      df = getSpreadInfo(nearest_df, currDay.Date[0], currDay.Year[0], currDay.Fire[0])\n","      \n","      # append df \n","      \n","      df = visualizeVectors(df, currDay.reset_index())\n","      complete_df_byFire.append(df)\n","  \n","  return complete_df_byFire"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qZSeXwdivWX_"},"source":["## Run Complete Spread "]},{"cell_type":"code","metadata":{"id":"9OOGUg3CNj0M"},"source":["# [TODO] fix direction (crs decimal degrees)\n","\n","interFiles = lstFiles(os.path.join(r'Products', 'By_Fire'), '.shp')\n","outpath = 'MultiSpread/CSV'\n","\n","for fire_poly in interFiles:\n","  nm = os.path.basename(fire_poly).replace('shp', 'csv')\n","  print(nm)\n","  if os.path.exists(os.path.join(outpath, nm)) == False:\n","    try: \n","      complete_df_byFire = []\n","      final_df = pd.concat(getFinalMagnitude(fire_poly)).reset_index(drop=True)\n","      final_df.to_csv(os.path.join(outpath, nm))\n","    except: \n","      print('error')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"chwbVug_CyV2"},"source":["# final_df = gpd.GeoDataFrame(final_df, geometry='start_coord')\n","\n","#   new_outpath = fire_poly.replace('Products', 'MultiSpread')\n","#   new_outpath = new_outpath.replace('By_Fire', 'Vectors')\n","#   new_outpath = new_outpath.replace('NAT', 'MultiSpreadVectors')\n","#   new_outpath = new_outpath.replace('shp', 'geojson')\n","\n","#   folderPath = os.path.dirname(new_outpath)\n","#   if not os.path.exists(folderPath):\n","#       os.makedirs(folderPath)\n","\n","#   print(new_outpath)\n","#   final_df.to_file(new_outpath, driver='GeoJSON')\n","\n","#   new_csv = new_outpath.replace('Vectors', 'CSV')\n","#   new_csv = new_csv.replace('shp', 'csv')\n","\n","#   csvfolderPath = os.path.dirname(new_csv)\n","#   if not os.path.exists(csvfolderPath):\n","#       os.makedirs(csvfolderPath)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zVZDlbo6McPs"},"source":["## Merge Into One CSV\n","Merge, upperquantile, median"]},{"cell_type":"code","metadata":{"id":"zsoAiNPuMf1I"},"source":["outpath = 'MultiSpread/CSV'\n","csv_list = lstFiles(outpath, '.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TNaEj5KRM2E4","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600918954408,"user_tz":420,"elapsed":1091,"user":{"displayName":"Erica Scaduto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_Xg3Y--EQFQ6RVDUS0SoJsVKUb6AOaaVkYu-7=s64","userId":"04192059296941555235"}},"outputId":"ebe0a2d6-1710-444c-90f6-7080b34d31bc"},"source":["len(csv_list)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["471"]},"metadata":{"tags":[]},"execution_count":201}]},{"cell_type":"code","metadata":{"id":"P05j_Po7M2Ij"},"source":["#combine all files in the list\n","combined_csv = pd.concat([pd.read_csv(f) for f in csv_list])\n","#export to csv\n","combined_csv.to_csv( \"MultiSpread/combined_magnitude_2012_2020.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KvUdjZSiQYj4"},"source":["from shapely import wkt\n","combined_csv['line_coord'] = combined_csv['line_coord'].apply(wkt.loads)\n","combined_csv['start_coord'] = combined_csv['start_coord'].apply(wkt.loads)\n","combined_csv['end_coord'] = combined_csv['end_coord'].apply(wkt.loads)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RH470_OsRuBt"},"source":["## Fix Direction"]},{"cell_type":"code","metadata":{"id":"vJoc9T8MPQ9e"},"source":["START_gpd = gpd.GeoDataFrame(combined_csv, geometry='start_coord', crs='EPSG:3310').reset_index(drop=True)\n","END_gpd = gpd.GeoDataFrame(combined_csv, geometry='end_coord', crs='EPSG:3310').reset_index(drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8eELtQo-R1NR"},"source":["START_gpd = START_gpd.to_crs('EPSG:4326')\n","END_gpd = END_gpd.to_crs('EPSG:4326')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BvY9-_sATYX7"},"source":["start_coord_list = list(zip(START_gpd.geometry.x, START_gpd.geometry.y))\n","end_coord_list = list(zip(END_gpd.geometry.x, END_gpd.geometry.y))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xqhSDSKKR1Vm"},"source":["directions = [calculate_initial_compass_bearing(x,y) for x,y in zip(start_coord_list,end_coord_list)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nHq9YlAFWGgC"},"source":["combined_csv['direction'] = directions\n","combined_csv['distance'] = combined_csv['line_distance']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KpMVkfaSWPo3"},"source":["combined_csv = combined_csv.drop(columns=['line_distance'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YxFLrBL-Wrhm"},"source":["combined_csv.to_csv( \"MultiSpread/combined_magnitude_2012_2020.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"68QjoKO1OnLl"},"source":["! pip install windrose"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0xcjk_GeN1U-"},"source":["from windrose import WindroseAxes\n","from matplotlib import pyplot as plt\n","import matplotlib.cm as cm\n","import numpy as np\n","import pandas as pd \n","import os\n","import seaborn as sns\n","from pylab import savefig"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8GzzxA-ZN0eD"},"source":["def windRosePlot(df, figurePath): \n","    ws = df['Direction'].values\n","    wd = df['line_distance'].values\n","    ax = WindroseAxes.from_ax()\n","    ax.contourf(ws, wd, cmap=cm.hot)\n","    ax.set_legend()\n","    ax.figure.savefig(figurePath + fr + \"_\" + str(yr) + '.png', dpi = 400)\n","    ax.figure.clf()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YV2Mi42hR139"},"source":["### Weighted Average Based on Distance"]},{"cell_type":"code","metadata":{"id":"RQaCk1rMO23e"},"source":["# Weighted Average DEF \n","def wavg(group, avg_name, weight_name):\n","    d = group[avg_name]\n","    w = group[weight_name]\n","    try:\n","        return (d * w).sum() / w.sum()\n","    except ZeroDivisionError:\n","        return d.mean()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZvyMmotDR_Sl"},"source":["### Upper and Lower Quartiles"]},{"cell_type":"code","metadata":{"id":"gk_ZBelAO4SL"},"source":["# find quartile \n","def quartiles(dataPoints):\n","    # check the input is not empty\n","    # 1. order the data set\n","    sortedPoints = sorted(dataPoints)\n","    # 2. divide the data set in two halves\n","    mid = len(sortedPoints) // 2 # uses the floor division to have integer returned\n","    if (len(sortedPoints) % 2 == 0):\n","        # even\n","        lowerQ = np.median(sortedPoints[:mid])\n","        upperQ = np.median(sortedPoints[mid:])\n","    else:\n","        # odd\n","        lowerQ = np.median(sortedPoints[:mid])  # same as even\n","        upperQ = np.median(sortedPoints[mid+1:])\n","    return (lowerQ, upperQ)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Y0waaC1fmMS"},"source":["FinalDF = pd.read_csv(r'MultiSpread/combined_magnitude_2012_2020.csv', index_col=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r9XJ2VQNjgDL"},"source":["# Upper/Lower Quartiles\n","lowerQuart = FinalDF.groupby(['Fire', \"Date\"], group_keys=False)['distance'].apply(lambda x: quartiles(x)[0]).reset_index()\n","upperQuart = FinalDF.groupby(['Fire', \"Date\"], group_keys=False)['distance'].apply(lambda x: quartiles(x)[1]).reset_index()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XV9CHST9j6OM"},"source":["quart = lowerQuart.merge(upperQuart, on=['Fire', \"Date\"])\n","quart.columns = ['Fire', \"Date\", 'Magnitude (lowerQ)', 'Magnitude (upperQ)']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F8UK8wmSfnDz"},"source":["# Weighted Average \n","weighted_Avg = FinalDF.groupby(['Fire', \"Date\"]).apply(wavg, \"direction\", \"distance\").reset_index()\n","weighted_Avg.columns = ['Fire', 'Date', '(DIR_Weighted)']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pEhRMXrif_pJ"},"source":["# Get Max, Median, STD of Distance\n","f = {'distance': ['max', 'median', 'std']}   \n","distance_stats = FinalDF.groupby(['Fire', \"Date\"]).agg(f).reset_index()\n","distance_stats.columns = ['Fire', 'Date', 'Magnitude (max)','Magnitude (median)','Magnitude (stdv)']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pyYat2lugbZi"},"source":["# Direction at Max Distance\n","dir_maxdist = FinalDF.loc[df.reset_index().groupby(['Fire', \"Date\"])['distance'].idxmax()].reset_index()\n","dir_maxdist = dir_maxdist[['Fire', 'Date', 'direction']]\n","dir_maxdist.columns = ['Fire', 'Date', 'DIR_MaxDist']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wYn89WwehTOV"},"source":["finalDF = weighted_Avg.merge(distance_stats, on=['Fire', \"Date\"])\n","finalDF = finalDF.merge(dir_maxdist, on=['Fire', \"Date\"]).round(3)\n","finalDF = finalDF.merge(quart, on=['Fire', \"Date\"]).round(3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zjGciKoOik0w"},"source":["finalDF['Magnitude (median)'] = finalDF['Magnitude (median)'].astype(str)\n","finalDF['Magnitude (stdv)'] = finalDF['Magnitude (stdv)'].astype(str)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bjS17xIRim0w"},"source":["finalDF['DIST_MEDSTD'] = finalDF[['Magnitude (median)', 'Magnitude (stdv)']].apply(lambda x: ' ± '.join(x[x.notnull()]), axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9vCZAibKk-Jw"},"source":["## Save Final Magnitude File"]},{"cell_type":"code","metadata":{"id":"VLT0GotAjMAs"},"source":["finalDF.to_csv('MultiSpread/daily_magnitude_2012_2020.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OGVBFzXKi0FJ"},"source":["finalDF"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5H6ud2m-SLlU"},"source":["### Create Plots, csv files for each fireyear instance"]},{"cell_type":"code","metadata":{"id":"hArJZHIcO6NN"},"source":["FinalDF = pd.read_csv(r'MultiSpread/combined_magnitude_2012_2020.csv', index_col=0)\n","\n","FR_YR_List = list(set(list(zip(FinalDF['Fire'], FinalDF['Year']))))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xg6VSDZveNb_","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600923642846,"user_tz":420,"elapsed":619,"user":{"displayName":"Erica Scaduto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_Xg3Y--EQFQ6RVDUS0SoJsVKUb6AOaaVkYu-7=s64","userId":"04192059296941555235"}},"outputId":"dd10a6a8-88c8-4e1b-97dd-4b7bd81b7aad"},"source":["len(FR_YR_List)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["471"]},"metadata":{"tags":[]},"execution_count":261}]},{"cell_type":"code","metadata":{"id":"fO2nVG41eUny","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600923644993,"user_tz":420,"elapsed":1651,"user":{"displayName":"Erica Scaduto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_Xg3Y--EQFQ6RVDUS0SoJsVKUb6AOaaVkYu-7=s64","userId":"04192059296941555235"}},"outputId":"38b61abb-3e11-4d86-e0c9-2f32c8d4524b"},"source":["sns.set(style=\"whitegrid\")\n","palette = sns.color_palette(\"mako_r\", 3)\n","rootPath = r\"MultiSpread/By_Fire\" \n","for fr, yr in FR_YR_List[:1]: \n","    print(fr, yr)\n","    \n","    flname = fr + \"_\" + str(yr) + \"_FinalAll.csv\"\n","    CSVPath = os.path.join(rootPath, str(yr), fr, \"FinalCSV\", flname)\n","    figurePath = createFolder(os.path.join(rootPath, str(yr), fr), \"Figures\")\n","\n","    df = FinalDF[(FinalDF['Fire'] == fr) & (FinalDF['Year'] == yr)]\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Blake 2015\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QJPRcXBtPF-v"},"source":["sns.set(style=\"whitegrid\")\n","palette = sns.color_palette(\"mako_r\", 3)\n","rootPath = r\"MultiSpread\" \n","for fr, yr in FR_YR_List: \n","    print(fr, yr)\n","    flname = fr + \"_\" + str(yr) + \"_FinalAll.csv\"\n","    CSVPath = os.path.join(rootPath, str(yr), fr, \"FinalCSV\", flname)\n","    figurePath = createFolder(os.path.join(rootPath, str(yr), fr), \"Figures\")\n","    \n","    df = pd.read_csv(CSVPath, index_col = 0) \n","    windRosePlot(df, figurePath)\n","    csvPath = createFolder(rootPath, \"SummaryCSV\")\n","    yrPath = createFolder(csvPath, str(yr))\n","    finalDF.to_csv(os.path.join(yrPath, csvName))\n","    # Plot the responses for different events and regions \n","    matplotlib.pyplot.close('all')\n","    finalDF['log(Area)'] = np.log(finalDF['Area (ha)'])\n","    melted = pd.melt(finalDF, id_vars=['JulianDay'], value_vars=['log(Area)', 'Magnitude (max)', 'Magnitude (median)'],\n","        var_name='Value Type', value_name='Values')\n","    melted['Values'] = melted['Values'].astype('float64')\n","    snsPLOT = sns.lineplot(x=\"JulianDay\", y=\"Values\", hue = 'Value Type', style = 'Value Type', palette = palette, data=melted)\n","    figure = snsPLOT.get_figure()    \n","    figure.savefig(figurePath + fr + \"_\" + str(yr) + \"_timeseries.png\", dpi = 400)\n","    matplotlib.pyplot.close('all')\n","    matplotlib.pyplot.clf()"],"execution_count":null,"outputs":[]}]}